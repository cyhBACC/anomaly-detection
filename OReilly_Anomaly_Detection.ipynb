{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Convert a dataset into a windowed format\n",
    "# For example:\n",
    "# window = 2\n",
    "# dataset =\n",
    "# [\n",
    "#  [1, 2, 3],\n",
    "#  [2, 3, 4],\n",
    "#  [5, 6, 7]\n",
    "# ]\n",
    "#\n",
    "# Will result in:\n",
    "# [\n",
    "#  [0, 0, 0, 0, 0, 0, 1, 2, 3],\n",
    "#  [0, 0, 0, 1, 2, 3, 2, 3, 4],\n",
    "#  [1, 2, 3, 2, 3, 4, 5, 6, 7]\n",
    "# ]\n",
    "def prepare_dataset(dataset, window):\n",
    "    windowed_data = []\n",
    "    # TODO append the first \"window\" rows padded with 0s\n",
    "    for i in range(len(dataset)-window-1):\n",
    "        observation = dataset[i:(i+window),]\n",
    "        windowed_data.append(observation)\n",
    "    return np.array(windowed_data)\n",
    "\n",
    "def load_prepared_dataset(path, window):\n",
    "    # Read training data into memory\n",
    "    data_raw = pd.read_csv(path)\n",
    "    \n",
    "    # Select training columns\n",
    "    data_selected_raw = data_raw[[\" LinAccX (g)\"]].as_matrix()\n",
    "    \n",
    "    return data_raw, prepare_dataset(data_selected_raw, window)\n",
    "    \n",
    "# How long \n",
    "window = 20\n",
    "\n",
    "# Load data used for training\n",
    "data_train_raw, data_train = load_prepared_dataset('resources/normal_20170202_2229.csv', window)\n",
    "# Load data used for testing/validating\n",
    "data_validate_raw, data_validate = load_prepared_dataset('resources/verify_20170202_2243.csv', window)\n",
    "\n",
    "# Number of columns = number of features * window\n",
    "features = data_train.shape[1] / window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.pylabtools import figsize\n",
    "figsize(16, 7)\n",
    "\n",
    "plt.plot(list(range(len(data_train_raw[\" LinAccX (g)\"]))), data_train_raw[\" LinAccX (g)\"], \"go\")\n",
    "plt.ylabel('LinAccX')\n",
    "plt.xlabel('Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(len(data_validate_raw[\" LinAccX (g)\"]))), data_validate_raw[\" LinAccX (g)\"], \"go\")\n",
    "plt.ylabel('LinAccX')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import nd, autograd, gluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ctx = mx.cpu()\n",
    "model_ctx = mx.cpu()\n",
    "# For machines with GPU - use this \n",
    "# model_ctx = mx.gpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_inputs = features\n",
    "num_outputs = features\n",
    "num_examples = data_train.shape[0]\n",
    "\n",
    "data_train_mxnet = mx.gluon.data.DataLoader(data_train, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden = 64\n",
    "net = gluon.nn.Sequential()\n",
    "with net.name_scope():\n",
    "    net.add(gluon.nn.Dense(num_hidden, activation=\"relu\"))\n",
    "    net.add(gluon.nn.Dense(num_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.collect_params().initialize(mx.init.Normal(sigma=.1), ctx=model_ctx)\n",
    "\n",
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': .01})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iterator, net):\n",
    "    acc = mx.metric.Accuracy()\n",
    "    for i, data in enumerate(data_iterator):\n",
    "        data = data.as_in_context(model_ctx).reshape((-1, features))\n",
    "        output = net(data)\n",
    "        # TODO make labels = np.array_fill(data.shape[0], 0)\n",
    "        # predictions = output - data \n",
    "        acc.update(preds=predictions, labels=label)\n",
    "    return acc.get()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "smoothing_constant = .01\n",
    "\n",
    "for e in range(epochs):\n",
    "    cumulative_loss = 0\n",
    "    for i, data in enumerate(train_data):\n",
    "        data = data.as_in_context(model_ctx).reshape((-1, 784))\n",
    "        with autograd.record():\n",
    "            output = net(data)\n",
    "            loss = softmax_cross_entropy(output, data)\n",
    "            loss.backward()\n",
    "        trainer.step(data.shape[0])\n",
    "        cumulative_loss += nd.sum(loss).asscalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO do predictions on all the data\n",
    "# Get the errors\n",
    "# Get threshold as sd(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO do predictions on all the test data\n",
    "# Check against threshold for anomalies\n",
    "# plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long-short term memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = mx.gluon.rnn.LSTM(features, 3)\n",
    "layer.initialize()\n",
    "output = layer(data_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
